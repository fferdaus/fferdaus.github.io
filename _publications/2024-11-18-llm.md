---
title: "LLM-Inference-Bench: Inference Benchmarking of Large Language Models on AI Accelerators"
collection: publications
category: conferences
permalink: /publication/2024-11-18-llm.md
excerpt: 'This paper introduces LLM-Inference-Bench, a comprehensive benchmarking suite to evaluate the hardware inference performance of LLMs by thoroughly analyzing diverse hardware platforms, including GPUs from Nvidia and AMD, as well as specialized AI accelerators such as Intel Habana and SambaNova.'
date: 2024-11-18
venue: 'SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis'
---

<!--slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
paperurl: 'http://academicpages.github.io/files/paper1.pdf'
bibtexurl: 'http://academicpages.github.io/files/bibtex1.bib'
citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'
---
The contents above will be part of a list of publications, if the user clicks the link for the publication than the contents of section will be rendered as a full page, allowing you to provide more information about the paper for the reader. When publications are displayed as a single page, the contents of the above "citation" field will automatically be included below this section in a smaller font.-->
